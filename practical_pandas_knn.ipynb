{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from sklearn.utils import shuffle # df=shuffle(df)\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('Iris.csv')\n",
    "#print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
      "0    4            4.6           3.1            1.5           0.2   \n",
      "1   59            6.6           2.9            4.6           1.3   \n",
      "2   88            6.3           2.3            4.4           1.3   \n",
      "3  145            6.7           3.3            5.7           2.5   \n",
      "4  141            6.7           3.1            5.6           2.4   \n",
      "\n",
      "           Species  \n",
      "0      Iris-setosa  \n",
      "1  Iris-versicolor  \n",
      "2  Iris-versicolor  \n",
      "3   Iris-virginica  \n",
      "4   Iris-virginica  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#sample(): returns a fraction of the original sample\n",
    "#reset_index(drop=True):drop parameter to avoid the old index being added as a column:\n",
    "df=df.sample(frac=1).reset_index(drop=True)#retain but shuffles data\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nALGORITHM\\n1. get the input and output(done)\\n2. convert output to one-hot encoding(done)\\n3. do the train-test split(done)\\n\\n4. find distance metric (done)\\n5. find k nearest neighbour\\n    5.1 find top k indices(done)\\n    5.2 find the associated top k values as one-hot encodings(done)\\n    5.3 add up the one-hot encodings for each value by axis=1(done)\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert(str):\n",
    "    if str == \"Iris-setosa\":\n",
    "        return 0\n",
    "    elif str == \"Iris-virginica\":\n",
    "        return 2\n",
    "    elif str == \"Iris-versicolor\":\n",
    "        return 1\n",
    "#indent\n",
    "\n",
    "X=np.array(df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']])#shape (150,4)\n",
    "Y=np.array(df['Species'].apply(convert))#get output shape(150,)\n",
    "\n",
    "Z=np.eye(len(set(Y)))[Y]#one-hot encodings shape(150,3)\n",
    "'''\n",
    "ALGORITHM\n",
    "1. get the input and output(done)\n",
    "2. convert output to one-hot encoding(done)\n",
    "3. do the train-test split(done)\n",
    "\n",
    "4. find distance metric (done)\n",
    "5. find k nearest neighbour\n",
    "    5.1 find top k indices(done)\n",
    "    5.2 find the associated top k values as one-hot encodings(done)\n",
    "    5.3 add up the one-hot encodings for each value by axis=1(done)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)#non-deterministic seeding\n",
    "\n",
    "#we are doing a 70:30 split\n",
    "train_indice=np.random.choice(len(X), round(len(X)*0.7), replace=False)\n",
    "test_indice=np.array(list(set(range(len(X))) - set(train_indice)))\n",
    "\n",
    "#passed within feed_dict\n",
    "Xtr=X[train_indice]\n",
    "Ytr=Z[train_indice]\n",
    "Xte=X[test_indice]\n",
    "Yte=Z[test_indice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(Xtr.shape)#features\n",
    "# print(Xte.shape)#test features\n",
    "\n",
    "# print(Ytr[0])#one-hot encoding\n",
    "# print(Xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "x_data_train=tf.placeholder(shape=[None,len(Xtr[0])],dtype=tf.float32)#feed_dict{x_data_train:Xtr}\n",
    "x_data_test=tf.placeholder(shape=[None,len(Xte[0])],dtype=tf.float32)#feed_dict{x_data_test:Xte}\n",
    "y_data_train=tf.placeholder(shape=[None,len(Ytr[0])],dtype=tf.float32)#feed_dict{y_data_train:Ytr}\n",
    "\n",
    "#MANHATTAN Distance\n",
    "distance=tf.reduce_sum(tf.abs(x_data_train - tf.expand_dims(x_data_test, 1)), axis=2)\n",
    "\n",
    "\n",
    "#transpose is expensive\n",
    "#reshape is cheap\n",
    "\n",
    "_,top_k_indice=tf.nn.top_k(tf.negative(distance),k=k)\n",
    "\n",
    "#the following line generates a set of of one-hot encodings\n",
    "#tf.gather(params,indices) accesses a set of values from \"params\" based on a set of \"indices\"\n",
    "top_k_label=tf.gather(y_data_train,top_k_indice)\n",
    "\n",
    "\n",
    "sum_up_predictions = tf.reduce_sum(top_k_label, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction=tf.argmax(sum_up_predictions ,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "prediction_outcome=sess.run(prediction,feed_dict={x_data_train:Xtr,x_data_test:Xte,y_data_train:Ytr})\n",
    "\n",
    "#print(sess.run(prediction,feed_dict={x_data_train:Xtr,x_data_test:Xte,y_data_train:Ytr}))\n",
    "\n",
    "\n",
    "#ADDING AN EXTRA DIMENSION\n",
    "# dummy=tf.expand_dims(x_data_test, 0)#[?,4] to shape = (1,?,4)\n",
    "# #tf.expand_dims(x_data_test, 1)#[?,4] to (?,1,4)\n",
    "# #tf.expand_dims(x_data_test, 2)#[?,4] to (?,4,1)\n",
    "# print(dummy.shape)\n",
    "# print(sess.run(dummy,feed_dict={x_data_test:Xte}))\n",
    "\n",
    "\n",
    "# tf.shape(top_k_label) #[45,5,3]\n",
    "# [[ 0.  1.  0.]\n",
    "#   [ 0.  1.  0.]\n",
    "#   [ 0.  1.  0.]\n",
    "#   [ 0.  0.  1.]\n",
    "#   [ 0.  0.  1.]]\n",
    "\n",
    "# tf.shape(sum_up_predictions) #[45,3]\n",
    "# [ 0.  3.  2.]\n",
    "\n",
    "# tf.shape(prediction) #[45]\n",
    "# 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "#FINDING THE ACCURACY\n",
    "accuracy=0\n",
    "for pred,actual in zip(prediction_outcome,Yte):\n",
    "    if pred == np.argmax(actual):\n",
    "        accuracy+= 1\n",
    "        \n",
    "print(accuracy/len(prediction_outcome))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
